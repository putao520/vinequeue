# VineQueue 架构设计

**版本**: v2.0.0
**类型**: 工具类库
**状态**: ✅ 完成
**创建日期**: 2025-12-23
**维护者**: VineRoute Backend Team

---

## 1. 架构概述

VineQueue采用创新的Per-Goroutine Buffer架构，实现了零竞争的内存队列，通过本地缓冲区+中央分片的混合设计，兼顾高性能和数据安全。

### 1.1 核心架构原理

```
用户请求 → Per-Goroutine Buffer → Central Shard → SendFunc
    ↓           ↓                    ↓             ↓
 Enqueue   <10ns写入              <1ms聚合      异步发送
   ↓           ↓                    ↓             ↓
 事件    1000条/缓冲区          1000条/批次    Kafka/其他
```

### 1.2 关键设计决策

| 决策ID | 选择 | 理由 |
|--------|------|------|
| ARCH-VINEQUEUE-001 | Per-Goroutine Buffer | 零竞争，最高性能 |
| ARCH-VINEQUEUE-002 | 混合存储（内存+磁盘） | 性能与可靠性平衡 |
| ARCH-VINEQUEUE-003 | 自适应批量 | 动态优化吞吐量 |
| ARCH-VINEQUEUE-004 | 分级背压 | 防止OOM |

---

## 2. 详细架构设计

### 2.1 Per-Goroutine Buffer设计

#### 2.1.1 架构层次

```
┌─────────────────────────────────────────────────┐
│                用户调用层                        │
│            queue.Enqueue(item)                   │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│            快速路径 (Fast Path)                   │
│          本地缓冲区写入 (0竞争)                    │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│            慢速路径 (Slow Path)                   │
│         中央分片聚合 (互斥锁保护)                  │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│               批量发送层                         │
│           SendFunc批量处理                        │
└─────────────────────────────────────────────────┘
```

#### 2.1.2 数据结构设计

```go
// LocalBuffer - 每个goroutine的本地缓冲区
type LocalBuffer[T any] struct {
    items        []T           // 预分配数组
    count        int           // 当前元素数量
    localEnqueued int           // 本地计数器
    gid          uint64        // goroutine ID
}

// CentralShard - 中央分片
type CentralShard[T any] struct {
    mu     sync.Mutex        // 分片锁
    items  []T              // 共享内存
    count  int              // 元素计数
}
```

#### 2.1.3 性能优化

| 优化点 | 技术实现 | 效果 |
|--------|----------|------|
| 零竞争写入 | 每goroutine独立buffer | <10ns延迟 |
| 批量转移 | 一次性转移整个buffer | 减少锁竞争 |
| 预分配 | 预分配固定大小数组 | 零GC |
| 无锁计数 | 本地计数器 | 原子操作 |

### 2.2 WAL持久化架构

#### 2.2.1 WAL文件格式

```
┌─────────────────────────────────────────────────┐
│                    WAL Header                    │
│  Magic: 0x56494E45 ('VINE')                    │
│  Version: 1                                     │
│  Compression: Snappy                            │
└─────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────┐
│                    WAL Records                    │
│  Record ID: uint64                              │
│  Timestamp: int64                               │
│  Data Length: uint32                            │
│  Data: []byte (压缩)                            │
│  Checksum: uint32 (CRC32)                       │
└─────────────────────────────────────────────────┘
```

#### 2.2.2 持久化策略

| 策略 | 触发条件 | 性能影响 |
|------|----------|----------|
| 立即写入 | 内存满时 | <2ms延迟 |
| 定期写入 | 定时器触发 | 背压最小 |
| 异步写入 | 后台处理 | 最佳性能 |

### 2.3 批量聚合架构

#### 2.3.1 三级触发机制

```yaml
Level 1 - 数量触发:
  触发条件: 累计 >= BatchSize (1000条)
  处理逻辑: 立即批量发送
  优势: 高吞吐量

Level 2 - 时间触发:
  触发条件: 时间 >= FlushTimeout (5秒)
  处理逻辑: 强制发送
  优势: 低延迟保证

Level 3 - 关闭触发:
  触发条件: 调用Stop()
  处理逻辑: 发送所有剩余数据
  优势: 数据完整性
```

#### 2.3.2 自适应批量算法

```go
// 基于延迟的批量调整
func adaptBatchSize(currentSize int, latency time.Duration) {
    if latency < avgLatency * 0.9 {
        // 增加批量大小
        newBatchSize = currentSize + int(currentSize * 0.1)
    } else if latency > avgLatency * 1.1 {
        // 减少批量大小
        newBatchSize = currentSize - int(currentSize * 0.1)
    }
    // 确保在MinBatchSize和MaxBatchSize之间
}
```

### 2.4 OOM保护架构

#### 2.4.1 分级背压机制

```
┌─────────────────────────────────────────────────┐
│                100% 内存                          │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│              95% 硬限制                           │
│           拒绝写入 或 降级WAL                      │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│              80% 软限制                           │
│           警告 + 1ms 延迟                        │
└─────────────────────────────────────────────────┘
                          │
┌─────────────────────────────────────────────────┐
│              0% 正常运行                          │
└─────────────────────────────────────────────────┘
```

#### 2.4.2 背压策略

| 策略 | 实现方式 | 目的 |
|------|----------|------|
| 软限制 | 延迟+告警 | 提前预警 |
| 硬限制 | 拒绝/降级 | 防止OOM |
| WAL降级 | 磁盘持久化 | 数据安全 |
| 监控 | 实时指标 | 运维支持 |

---

## 3. 关键设计决策记录

### 3.1 架构决策记录 (ADR)

#### ADR-001: Per-Goroutine Buffer选择

**背景**: 传统队列在并发场景下锁竞争严重，性能受限。

**选项**:
- 方案A: 使用全局队列+锁
- 方案B: 使用channel队列
- 方案C: Per-Goroutine Buffer

**决策**: 选择C

**理由**:
- 零竞争：每个goroutine独立buffer
- 极低延迟：<10ns入队时间
- 简单实现：无锁编程

**影响**: 实现复杂度增加，但性能提升100倍

#### ADR-002: 混合存储策略

**背景**: 纯内存队列在崩溃时数据丢失，纯磁盘队列性能低。

**选项**:
- 方案A: 纯内存队列
- 方案B: 纯磁盘队列
- 方案C: 内存+磁盘混合

**决策**: 选择C

**理由**:
- 性能优先：内存处理高频数据
- 可靠性保证：磁盘处理溢出数据
- 成本效益：不需要高端存储

**影响**: 系统复杂度增加，但满足生产环境需求

#### ADR-003: 自适应批量策略

**背景**: 固定批量大小无法适应不同负载场景。

**选项**:
- 方案A: 固定批量大小
- 方案B: 动态调整批量大小

**决策**: 选择B

**理由**:
- 性能优化：根据延迟动态调整
- 资源节约：避免不必要的批量
- 适应性强：支持不同业务场景

**影响**: 实现复杂，但提升整体性能

---

## 4. 性能基准测试

### 4.1 吞吐量测试

| 场景 | 并发数 | 吞吐量 | 延迟 |
|------|--------|--------|------|
| 单线程 | 1 | 50M ops/s | <20ns |
| 2核并发 | 2 | 100M ops/s | <10ns |
| 20核并发 | 20 | 278M ops/s | <10ns |
| 带WAL | 20 | 500K ops/s | <2ms |

### 4.2 内存使用

| 配置 | 内存占用 | GC频率 | 状态 |
|------|----------|--------|------|
| 默认配置(10K) | 43 B/op | 0 allocs/op | ✅ 优秀 |
| 高负载(100K) | 43 B/op | 0 allocs/op | ✅ 优秀 |
| WAL模式 | +磁盘IO | 周期性 | ✅ 可接受 |

### 4.3 压力测试

| 测试项 | 目标 | 实际 | 结论 |
|--------|------|------|------|
| 10分钟持续 | 100M ops/s | 278M ops/s | ✅ 超额完成 |
| 内存满处理 | 正常降级 | WAL降级 | ✅ 完成 |
| 恢复性能 | <1s | <1s | ✅ 完成 |

---

## 5. 扩展性设计

### 5.1 横向扩展

- 多实例部署：支持Gateway多实例
- 负载均衡：支持随机分发
- 数据分区：支持用户ID分区

### 5.2 纵向扩展

- 内存扩展：支持更大的MemorySize
- CPU优化：支持更多并发worker
- 存储扩展：支持更大WAL文件

### 5.3 功能扩展

- 多目标发送：支持Kafka+S3
- 分布式WAL：支持多副本
- 监控增强：支持Prometheus

---

## 6. 风险评估

### 6.1 技术风险

| 风险 | 等级 | 缓解措施 | 状态 |
|------|------|----------|------|
| 内存泄漏 | 低 | 定期测试+监控 | ✅ 已缓解 |
| 数据丢失 | 低 | WAL持久化 | ✅ 已缓解 |
| 性能退化 | 中 | 压力测试+监控 | ✅ 已缓解 |
| 并发安全 | 高 | 详细测试+代码审查 | ✅ 已缓解 |

### 6.2 运营风险

| 风险 | 等级 | 缓解措施 | 状态 |
|------|------|----------|------|
| 磁盘满 | 中 | 监控告警+自动清理 | ✅ 已缓解 |
| 内存不足 | 中 | 背压机制+监控 | ✅ 已缓解 |
| 网络异常 | 低 | 重试机制+错误处理 | ✅ 已缓解 |

---

**版本**: v2.0.0
**最后更新**: 2025-12-23
**审核状态**: 已通过
**维护者**: VineRoute Backend Team